{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d26wnhw_2f3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9980dce9-8936-4d9d-d320-2db05aa77679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox48zQVG2gxv",
        "outputId": "04aea477-7954-4094-cf3e-b38de3b03ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abseiling', 'air drumming']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "\n",
        "dataset_path = os.listdir(r'/content/drive/MyDrive/Dataset/Dataset')\n",
        "\n",
        "label_types = os.listdir(r'/content/drive/MyDrive/Dataset/Dataset')\n",
        "print (label_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g17bKDQS3kuz"
      },
      "source": [
        "Preparing Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdzbp2Mq3gyO"
      },
      "source": [
        "Preparing Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HZQ0R5S3x7j",
        "outputId": "e4282072-280f-4165-bea8-0fb60804f00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-hz7iawey\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-hz7iawey\n",
            "  Resolved https://github.com/tensorflow/docs to commit 5d7c4c291249a7c7e149316ef0ac5eb86fd2cda1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor (from tensorflow-docs==0.0.0.dev0)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.8.0)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.3.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (3.3.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=183463 sha256=97c0d328b855b989631ae325ea51f1e25d47e86c4b3a393d249e3ae52738aa14\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bfrtpq5h/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: astor, tensorflow-docs\n",
            "Successfully installed astor-0.8.1 tensorflow-docs-0.0.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXvlEveM3scC"
      },
      "outputs": [],
      "source": [
        "#from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k-mboxp3v5h"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR6Mdhxx370_"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuA8BAty4Mow"
      },
      "source": [
        "Feed the videos to a network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovZusFnB5fri"
      },
      "source": [
        "VIT Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d1qfg_t5NK2",
        "outputId": "5cdd9981-ea71-41e5-c523-e315d438176c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxXob8VkAnPg"
      },
      "source": [
        "Frame Extraction Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p43BL8m9M9b",
        "outputId": "c247d6f7-13c9-433d-fa53-9e9bd377fa16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frames extraction completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import imageio\n",
        "import cv2\n",
        "# Set up paths\n",
        "Sequence_length=5\n",
        "IMAGE_HEIGHT , IMAGE_WIDTH= 224, 224\n",
        "data_dir = \"/content/drive/MyDrive/Dataset/Dataset\"\n",
        "frames_dir = \"/content/drive/MyDrive/Dataset/Model_Save\"\n",
        "\n",
        "# Get class names and their corresponding directories\n",
        "classes_dir = data_dir\n",
        "class_names = os.listdir(classes_dir)\n",
        "class_dirs = [os.path.join(classes_dir, c) for c in class_names]\n",
        "\n",
        "# Loop over each class directory\n",
        "for i, class_dir in enumerate(class_dirs):\n",
        "    # Create a directory to store the frames\n",
        "    frames_class_dir = os.path.join(frames_dir, class_names[i])\n",
        "    os.makedirs(frames_class_dir, exist_ok=True)\n",
        "\n",
        "    # Loop over each video file in the class directory\n",
        "    for video_file in os.listdir(class_dir):\n",
        "        video_path = os.path.join(class_dir, video_file)\n",
        "        video_name = os.path.splitext(video_file)[0]\n",
        "\n",
        "        # Create a directory to store the frames for this video\n",
        "        frames_video_dir = os.path.join(frames_class_dir, video_name)\n",
        "       # os.makedirs(frames_video_dir, exist_ok=True)\n",
        "\n",
        "        # Read the video and extract its frames\n",
        "        reader = cv2.VideoCapture(video_path)\n",
        "        video_frames_count = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        skip_frames_window = max(int(video_frames_count/Sequence_length), 1)\n",
        "        \n",
        "        for frame_counter in range(Sequence_length):\n",
        "            \n",
        "        # Set the current frame position of the video.\n",
        "            reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "            # Reading the frame from the video. \n",
        "            success, frame = reader.read() \n",
        "\n",
        "            # Check if Video frame is not successfully read then break the loop\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            # Resize the Frame to fixed height and width.\n",
        "            resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "            frame_path = os.path.join(frames_class_dir, f\"{frame_counter * skip_frames_window}.jpg\")\n",
        "            imageio.imwrite(frame_path, resized_frame)\n",
        "          \n",
        "        reader.release()\n",
        "\n",
        "\n",
        "print(\"Frames extraction completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3XDNCcLHCgL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu3IXX9lI4KC",
        "outputId": "c6dfa852-fd2d-41da-c958-2eacedd2ba09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ]
        }
      ],
      "source": [
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v8MTy8PMI9-7"
      },
      "outputs": [],
      "source": [
        "import patoolib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "GIK4hQ6AJGdd",
        "outputId": "9757653a-7660-420f-bc53-f59b55f3c214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/drive/MyDrive/Frame Dataset.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_5x4n6kr9 -- \"/content/drive/MyDrive/Frame Dataset.zip\"\n",
            "patool: ... /content/drive/MyDrive/Frame Dataset.zip extracted to `Frame Dataset'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Frame Dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "patoolib.extract_archive(\"/content/drive/MyDrive/Frame Dataset.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "th-ae94NV6E0"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "# We use a butterfly dataset of 50 species to demonstrate the classification method\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zevFGE7h0WQ6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T # for simplifying the transforms\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXqAEwLP0XrS",
        "outputId": "8a6229ad-c0b8-405f-9872-406f2b1fc662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ],
      "source": [
        "## Now, we import timm, torchvision image models\n",
        "!pip install timm # kaggle doesnt have it installed by default\n",
        "import timm\n",
        "from timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OHvIxZW_0Y92"
      },
      "outputs": [],
      "source": [
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iyo6KhIP0aNb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lK6sMD0u0bzx"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wA7nFt720dSj"
      },
      "outputs": [],
      "source": [
        "def get_classes(data_dir):\n",
        "    all_data = datasets.ImageFolder(data_dir)\n",
        "    return all_data.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lgWf9T-T0fFR"
      },
      "outputs": [],
      "source": [
        "def get_data_loaders(data_dir, batch_size, train = False):\n",
        "    if train:\n",
        "        #train\n",
        "        transform = T.Compose([\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n",
        "            T.Resize(256),\n",
        "            T.CenterCrop(224),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n",
        "            T.RandomErasing(p=0.2, value='random')\n",
        "        ])\n",
        "        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform = transform)\n",
        "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "        return train_loader, len(train_data)\n",
        "    else:\n",
        "        # val/test\n",
        "        transform = T.Compose([ # We dont need augmentation for test transforms\n",
        "            T.Resize(256),\n",
        "            T.CenterCrop(224),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n",
        "        ])\n",
        "        val_data = datasets.ImageFolder(os.path.join(data_dir, \"val/\"), transform=transform)\n",
        "        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n",
        "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "        return val_loader, test_loader, len(val_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3CGLDQNhku1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Bu1B8dwXzW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3871fOSy0iBG"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/Frame Dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hxtG3Dji0jP6"
      },
      "outputs": [],
      "source": [
        "(train_loader, train_data_len) = get_data_loaders(dataset_path, 128, train=True)\n",
        "(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(dataset_path, 128, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO9iy5YE0kjS",
        "outputId": "2979f57e-f4d3-4cfb-a2fe-c6d30853842b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abseiling', 'air drumming', 'answering questions', 'applauding', 'applying cream', 'archery', 'arm wrestling', 'arranging flowers', 'assembling computer', 'auctioning', 'baby waking up', 'baking cookies', 'balloon blowing', 'bandaging', 'barbequing', 'bartending', 'beatboxing', 'bee keeping', 'belly dancing', 'bench pressing', 'bending back', 'bending metal', 'biking through snow', 'blasting sand', 'blowing glass', 'blowing leaves', 'blowing nose', 'blowing out candles', 'bobsledding', 'bookbinding', 'bouncing on trampoline', 'bowling', 'braiding hair', 'breading or breadcrumbing', 'breakdancing', 'brush painting', 'brushing hair', 'brushing teeth', 'building cabinet', 'building shed', 'bungee jumping', 'busking', 'canoeing or kayaking', 'capoeira', 'carrying baby', 'cartwheeling', 'carving pumpkin', 'catching fish', 'catching or throwing baseball', 'catching or throwing frisbee', 'catching or throwing softball', 'celebrating', 'changing oil', 'changing wheel', 'checking tires', 'cheerleading', 'chopping wood', 'clapping', 'clay pottery making', 'clean and jerk', 'cleaning floor', 'cleaning gutters', 'cleaning pool', 'cleaning shoes', 'cleaning toilet', 'cleaning windows', 'climbing a rope', 'climbing ladder', 'climbing tree', 'contact juggling', 'cooking chicken', 'cooking egg', 'cooking on campfire', 'cooking sausages', 'counting money', 'country line dancing', 'cracking neck', 'crawling baby', 'crossing river', 'crying', 'curling hair', 'cutting nails', 'cutting pineapple', 'cutting watermelon', 'dancing ballet', 'dancing charleston', 'dancing gangnam style', 'dancing macarena', 'deadlifting', 'decorating the christmas tree', 'digging', 'dining', 'disc golfing', 'diving cliff', 'dodgeball', 'doing aerobics', 'doing laundry', 'doing nails', 'drawing', 'dribbling basketball', 'drinking', 'drinking beer', 'drinking shots', 'driving car', 'driving tractor', 'drop kicking', 'drumming fingers', 'dunking basketball', 'dying hair', 'eating burger', 'eating cake', 'eating carrots', 'eating chips', 'eating doughnuts', 'eating hotdog', 'eating ice cream', 'eating spaghetti', 'eating watermelon', 'egg hunting', 'exercising arm', 'exercising with an exercise ball', 'extinguishing fire', 'faceplanting', 'feeding birds', 'feeding fish', 'feeding goats', 'filling eyebrows', 'finger snapping', 'fixing hair', 'flipping pancake', 'flying kite', 'folding clothes', 'folding napkins', 'folding paper', 'front raises', 'frying vegetables', 'garbage collecting', 'gargling', 'getting a haircut', 'getting a tattoo', 'giving or receiving award', 'golf chipping', 'golf driving', 'golf putting', 'grinding meat', 'grooming dog', 'grooming horse', 'gymnastics tumbling', 'hammer throw', 'headbanging', 'headbutting', 'high jump', 'high kick', 'hitting baseball', 'hockey stop', 'holding snake', 'hopscotch', 'hoverboarding', 'hugging', 'hula hooping', 'hurdling', 'hurling (sport)', 'ice climbing', 'ice fishing', 'ice skating', 'ironing', 'javelin throw', 'jetskiing', 'jogging', 'juggling balls', 'juggling fire', 'juggling soccer ball', 'jumping into pool', 'jumpstyle dancing', 'kicking field goal', 'kicking soccer ball', 'kissing', 'kitesurfing', 'knitting', 'krumping', 'laughing', 'laying bricks', 'long jump', 'lunge', 'making a cake', 'making a sandwich', 'making bed', 'making jewelry', 'making pizza', 'making snowman', 'making sushi', 'making tea', 'marching', 'massaging back', 'massaging feet', 'massaging legs', \"massaging person's head\", 'milking cow', 'mopping floor', 'motorcycling', 'moving furniture', 'mowing lawn', 'news anchoring', 'opening bottle', 'opening present', 'paragliding', 'parasailing', 'parkour', 'passing American football (in game)', 'passing American football (not in game)', 'peeling apples', 'peeling potatoes', 'petting animal (not cat)', 'petting cat', 'picking fruit', 'planting trees', 'plastering', 'playing accordion', 'playing badminton', 'playing bagpipes', 'playing basketball', 'playing bass guitar', 'playing cards', 'playing cello', 'playing chess', 'playing clarinet', 'playing controller', 'playing cricket', 'playing cymbals', 'playing didgeridoo', 'playing drums', 'playing flute', 'playing guitar', 'playing harmonica', 'playing harp', 'playing ice hockey', 'playing keyboard', 'playing kickball', 'playing monopoly', 'playing organ', 'playing paintball', 'playing piano', 'playing poker', 'playing recorder', 'playing saxophone', 'playing squash or racquetball', 'playing tennis', 'playing trombone', 'playing trumpet', 'playing ukulele', 'playing violin', 'playing volleyball', 'playing xylophone', 'pole vault', 'presenting weather forecast', 'pull ups', 'pumping fist', 'pumping gas', 'punching bag', 'punching person (boxing)', 'push up', 'pushing car', 'pushing cart', 'pushing wheelchair', 'reading book', 'reading newspaper', 'recording music', 'riding a bike', 'riding camel', 'riding elephant', 'riding mechanical bull', 'riding mountain bike', 'riding mule', 'riding or walking with horse', 'riding scooter', 'riding unicycle', 'ripping paper', 'robot dancing', 'rock climbing', 'rock scissors paper', 'roller skating', 'running on treadmill', 'sailing', 'salsa dancing', 'sanding floor', 'scrambling eggs', 'scuba diving', 'setting table', 'shaking hands', 'shaking head', 'sharpening knives', 'sharpening pencil', 'shaving head', 'shaving legs', 'shearing sheep', 'shining shoes', 'shooting basketball', 'shooting goal (soccer)', 'shot put', 'shoveling snow', 'shredding paper', 'shuffling cards', 'side kick', 'sign language interpreting', 'singing', 'situp', 'skateboarding', 'ski jumping', 'skiing (not slalom or crosscountry)', 'skiing crosscountry', 'skiing slalom', 'skipping rope', 'skydiving', 'slacklining', 'slapping', 'sled dog racing', 'smoking', 'smoking hookah', 'snatch weight lifting', 'sneezing', 'sniffing', 'snorkeling', 'snowboarding', 'snowkiting', 'snowmobiling', 'somersaulting', 'spinning poi', 'spray painting', 'spraying', 'springboard diving', 'squat', 'sticking tongue out', 'stomping grapes', 'stretching arm', 'stretching leg', 'strumming guitar', 'surfing crowd', 'surfing water', 'sweeping floor', 'swimming backstroke', 'swimming breast stroke', 'swimming butterfly stroke', 'swing dancing', 'swinging legs', 'swinging on something', 'sword fighting', 'tai chi', 'taking a shower', 'tango dancing', 'tap dancing', 'tapping guitar', 'tapping pen', 'tasting beer', 'tasting food', 'testifying', 'texting', 'throwing axe', 'throwing ball', 'throwing discus', 'tickling', 'tobogganing', 'tossing coin', 'tossing salad', 'training dog', 'trapezing', 'trimming or shaving beard', 'trimming trees', 'triple jump', 'tying bow tie', 'tying knot (not on a tie)', 'tying tie', 'unboxing', 'unloading truck', 'using computer', 'using remote controller (not gaming)', 'using segway', 'vault', 'waiting in line', 'walking the dog', 'washing dishes', 'washing feet', 'washing hair', 'washing hands', 'water skiing', 'water sliding', 'watering plants', 'waxing back', 'waxing chest', 'waxing eyebrows', 'waxing legs', 'weaving basket', 'welding', 'whistling', 'windsurfing', 'wrapping present', 'wrestling', 'writing', 'yawning', 'yoga', 'zumba'] 400\n"
          ]
        }
      ],
      "source": [
        "classes = get_classes(\"/content/Frame Dataset/train\")\n",
        "print(classes, len(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "09keSH6W0mQ-"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": val_loader\n",
        "}\n",
        "dataset_sizes = {\n",
        "    \"train\": train_data_len,\n",
        "    \"val\": valid_data_len\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SCgQQND0pAL",
        "outputId": "bd1d227d-ba13-43e9-8960-b193fc439275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "399 76\n",
            "50960 9727\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader), len(val_loader))\n",
        "print(train_data_len, valid_data_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubDW_JOz0sUk",
        "outputId": "9937c811-d60d-4c0c-8322-a5cbbd737d7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# now, for the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Number of GPUs available:\", torch.cuda.device_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyrdVoDKCQGN",
        "outputId": "4579bed9-07e0-4405-eef5-1375c029e179"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPUs available: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k3Nf2qL0uaD",
        "outputId": "4224956f-3d50-4e1e-d3f2-e6f89b242864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\" to /root/.cache/torch/hub/checkpoints/deit_tiny_patch16_224-a1311bcf.pth\n",
            "100%|██████████| 21.9M/21.9M [00:00<00:00, 62.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri63c4L3TapN",
        "outputId": "5d90afb0-aec7-47b2-d170-f2d178f67ab8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n",
            "100%|██████████| 330M/330M [00:03<00:00, 95.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EcVjaZLCfoKe"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtyYtLie0wmP",
        "outputId": "fcddb38a-2eee-40dd-e633-168c14da8ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.3, inplace=False)\n",
            "  (3): Linear(in_features=512, out_features=400, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters(): #freeze model\n",
        "    param.requires_grad = False\n",
        "\n",
        "n_inputs = model.head.in_features\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 512),\n",
        "    nn.ReLU(),\n",
        "    #nn.GELU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, len(classes))\n",
        ")\n",
        "model = model.to(device)\n",
        "print(model.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6nkcwomeBhL",
        "outputId": "49f78e6a-49cf-4a42-92ac-3f8296415f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (patch_drop): Identity()\n",
            "  (norm_pre): Identity()\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (fc_norm): Identity()\n",
            "  (head_drop): Dropout(p=0.0, inplace=False)\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=400, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9k6EQb8M0yTX"
      },
      "outputs": [],
      "source": [
        "criterion = LabelSmoothingCrossEntropy()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zjyzlt8A00oF"
      },
      "outputs": [],
      "source": [
        "# lr scheduler\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kemOXAih02uj"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=18):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print(\"-\"*10)\n",
        "        \n",
        "        for phase in ['train', 'val']: # We do training and validation phase per epoch\n",
        "            if phase == 'train':\n",
        "                model.train() # model to training mode\n",
        "            else:\n",
        "                model.eval() # model to evaluate\n",
        "            \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "            \n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) # used for accuracy\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "            if phase == 'train':\n",
        "                scheduler.step() # step at end of epoch\n",
        "            \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n",
        "        print()\n",
        "    time_elapsed = time.time() - since # slight error\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, lambda_reg, num_epochs=18):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print(\"-\" * 10)\n",
        "        \n",
        "        for phase in ['train', 'val']: # We do training and validation phase per epoch\n",
        "            if phase == 'train':\n",
        "                model.train() # model to training mode\n",
        "            else:\n",
        "                model.eval() # model to evaluate\n",
        "            \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "            \n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) # used for accuracy\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        # Regularization\n",
        "                        regularization_loss = 0\n",
        "                        for param in model.parameters():\n",
        "                            regularization_loss += torch.norm(param)\n",
        "\n",
        "                        # Add regularization to the loss\n",
        "                        loss += lambda_reg * regularization_loss\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "            if phase == 'train':\n",
        "                scheduler.step() # step at end of epoch\n",
        "            \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n",
        "        print()\n",
        "    \n",
        "    time_elapsed = time.time() - since # slight error\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "yCmOuqHesR06"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_reg = 0.01"
      ],
      "metadata": {
        "id": "R0soo3pYuqoY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us-M-99v05mo",
        "outputId": "f6bfaa3f-3938-4f28-aad5-378bc51596dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:16<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 4.1415 Acc: 0.2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.5723 Acc: 0.3508\n",
            "\n",
            "Epoch 1/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.8417 Acc: 0.5303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.4665 Acc: 0.3757\n",
            "\n",
            "Epoch 2/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.4515 Acc: 0.6354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.4899 Acc: 0.3786\n",
            "\n",
            "Epoch 3/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:10<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.2223 Acc: 0.7048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.5356 Acc: 0.3756\n",
            "\n",
            "Epoch 4/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.0712 Acc: 0.7471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.5688 Acc: 0.3768\n",
            "\n",
            "Epoch 5/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.9681 Acc: 0.7787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.6040 Acc: 0.3736\n",
            "\n",
            "Epoch 6/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.8760 Acc: 0.8074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.6466 Acc: 0.3687\n",
            "\n",
            "Epoch 7/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:10<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.8101 Acc: 0.8296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.6634 Acc: 0.3683\n",
            "\n",
            "Epoch 8/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.7583 Acc: 0.8424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.6831 Acc: 0.3652\n",
            "\n",
            "Epoch 9/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.7066 Acc: 0.8585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.6918 Acc: 0.3644\n",
            "\n",
            "Epoch 10/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:10<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.6704 Acc: 0.8690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.7169 Acc: 0.3653\n",
            "\n",
            "Epoch 11/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:10<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.6332 Acc: 0.8832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.7380 Acc: 0.3643\n",
            "\n",
            "Epoch 12/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.6064 Acc: 0.8915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.7491 Acc: 0.3661\n",
            "\n",
            "Epoch 13/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:10<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.5784 Acc: 0.8987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.7656 Acc: 0.3654\n",
            "\n",
            "Epoch 14/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:12<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.5592 Acc: 0.9052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.7804 Acc: 0.3563\n",
            "\n",
            "Epoch 15/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.5350 Acc: 0.9110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.7947 Acc: 0.3578\n",
            "\n",
            "Epoch 16/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:10<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.5234 Acc: 0.9157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.8070 Acc: 0.3626\n",
            "\n",
            "Epoch 17/17\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [09:11<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.5056 Acc: 0.9187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:47<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.8322 Acc: 0.3588\n",
            "\n",
            "Training complete in 197m 32s\n",
            "Best Val Acc: 0.3786\n"
          ]
        }
      ],
      "source": [
        "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler) # now it is a lot faster\n",
        "# I will come back after 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FJn6ZerK4rQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31a3ef7-3968-4e18-f286-db43db2b790e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 212/212 [00:49<00:00,  4.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0030\n",
            "Test Accuracy of abseiling: 51% (33/64)\n",
            "Test Accuracy of air drumming:  1% ( 1/55)\n",
            "Test Accuracy of answering questions:  0% ( 0/18)\n",
            "Test Accuracy of applauding:  0% ( 0/11)\n",
            "Test Accuracy of applying cream: 15% ( 2/13)\n",
            "Test Accuracy of archery: 10% ( 6/58)\n",
            "Test Accuracy of arm wrestling: 13% ( 8/61)\n",
            "Test Accuracy of arranging flowers: 73% (22/30)\n",
            "Test Accuracy of assembling computer: 50% (11/22)\n",
            "Test Accuracy of auctioning:  0% ( 0/22)\n",
            "Test Accuracy of baby waking up: 20% ( 5/24)\n",
            "Test Accuracy of baking cookies: 17% ( 8/46)\n",
            "Test Accuracy of balloon blowing: 58% (21/36)\n",
            "Test Accuracy of bandaging:  0% ( 0/30)\n",
            "Test Accuracy of barbequing: 20% (10/48)\n",
            "Test Accuracy of bartending: 64% (18/28)\n",
            "Test Accuracy of beatboxing:  2% ( 1/48)\n",
            "Test Accuracy of bee keeping: 61% (13/21)\n",
            "Test Accuracy of belly dancing:  9% ( 4/44)\n",
            "Test Accuracy of bench pressing: 24% (12/49)\n",
            "Test Accuracy of bending back:  0% ( 0/24)\n",
            "Test Accuracy of bending metal:  0% ( 0/17)\n",
            "Test Accuracy of biking through snow: 35% (19/53)\n",
            "Test Accuracy of blasting sand: 21% ( 8/38)\n",
            "Test Accuracy of blowing glass: 55% (27/49)\n",
            "Test Accuracy of blowing leaves:  0% ( 0/20)\n",
            "Test Accuracy of blowing nose:  0% ( 0/25)\n",
            "Test Accuracy of blowing out candles: 21% (13/60)\n",
            "Test Accuracy of bobsledding: 19% ( 6/31)\n",
            "Test Accuracy of bookbinding: 77% (34/44)\n",
            "Test Accuracy of bouncing on trampoline: 28% ( 7/25)\n",
            "Test Accuracy of bowling: 50% (22/44)\n",
            "Test Accuracy of braiding hair: 18% ( 4/22)\n",
            "Test Accuracy of breading or breadcrumbing: 25% ( 6/24)\n",
            "Test Accuracy of breakdancing: 10% ( 4/38)\n",
            "Test Accuracy of brush painting: 16% ( 5/30)\n",
            "Test Accuracy of brushing hair:  4% ( 2/42)\n",
            "Test Accuracy of brushing teeth: 36% (21/57)\n",
            "Test Accuracy of building cabinet: 54% (12/22)\n",
            "Test Accuracy of building shed: 45% ( 9/20)\n",
            "Test Accuracy of bungee jumping: 25% (12/48)\n",
            "Test Accuracy of busking: 17% ( 7/40)\n",
            "Test Accuracy of canoeing or kayaking: 35% (22/62)\n",
            "Test Accuracy of capoeira: 19% (11/56)\n",
            "Test Accuracy of carrying baby:  7% ( 2/27)\n",
            "Test Accuracy of cartwheeling:  0% ( 0/18)\n",
            "Test Accuracy of carving pumpkin: 53% (15/28)\n",
            "Test Accuracy of catching fish: 11% ( 3/26)\n",
            "Test Accuracy of catching or throwing baseball:  2% ( 1/41)\n",
            "Test Accuracy of catching or throwing frisbee:  0% ( 0/35)\n",
            "Test Accuracy of catching or throwing softball: 24% (11/45)\n",
            "Test Accuracy of celebrating:  0% ( 0/25)\n",
            "Test Accuracy of changing oil: 33% (12/36)\n",
            "Test Accuracy of changing wheel:  0% ( 0/13)\n",
            "Test Accuracy of checking tires: 21% ( 7/32)\n",
            "Test Accuracy of cheerleading: 56% (32/57)\n",
            "Test Accuracy of chopping wood: 12% ( 6/50)\n",
            "Test Accuracy of clapping:  9% ( 2/21)\n",
            "Test Accuracy of clay pottery making: 25% ( 4/16)\n",
            "Test Accuracy of clean and jerk: 26% (11/42)\n",
            "Test Accuracy of cleaning floor: 23% (10/43)\n",
            "Test Accuracy of cleaning gutters:  5% ( 1/18)\n",
            "Test Accuracy of cleaning pool: 45% (10/22)\n",
            "Test Accuracy of cleaning shoes: 17% ( 5/28)\n",
            "Test Accuracy of cleaning toilet: 84% (21/25)\n",
            "Test Accuracy of cleaning windows: 38% (14/36)\n",
            "Test Accuracy of climbing a rope:  0% ( 0/22)\n",
            "Test Accuracy of climbing ladder:  0% ( 0/35)\n",
            "Test Accuracy of climbing tree: 26% (14/52)\n",
            "Test Accuracy of contact juggling:  7% ( 4/52)\n",
            "Test Accuracy of cooking chicken: 35% (19/54)\n",
            "Test Accuracy of cooking egg: 13% ( 3/22)\n",
            "Test Accuracy of cooking on campfire: 31% ( 6/19)\n",
            "Test Accuracy of cooking sausages:  5% ( 1/20)\n",
            "Test Accuracy of counting money: 42% (11/26)\n",
            "Test Accuracy of country line dancing:  5% ( 3/57)\n",
            "Test Accuracy of cracking neck:  0% ( 0/17)\n",
            "Test Accuracy of crawling baby: 37% (23/61)\n",
            "Test Accuracy of crossing river: 50% (26/51)\n",
            "Test Accuracy of crying:  6% ( 2/32)\n",
            "Test Accuracy of curling hair: 15% ( 5/32)\n",
            "Test Accuracy of cutting nails:  0% ( 0/26)\n",
            "Test Accuracy of cutting pineapple: 84% (27/32)\n",
            "Test Accuracy of cutting watermelon: 55% (21/38)\n",
            "Test Accuracy of dancing ballet: 24% (10/41)\n",
            "Test Accuracy of dancing charleston:  0% ( 0/36)\n",
            "Test Accuracy of dancing gangnam style:  0% ( 0/40)\n",
            "Test Accuracy of dancing macarena: 26% (11/42)\n",
            "Test Accuracy of deadlifting: 20% ( 7/35)\n",
            "Test Accuracy of decorating the christmas tree: 44% (16/36)\n",
            "Test Accuracy of digging:  4% ( 1/24)\n",
            "Test Accuracy of dining: 41% (15/36)\n",
            "Test Accuracy of disc golfing:  0% ( 0/21)\n",
            "Test Accuracy of diving cliff: 51% (23/45)\n",
            "Test Accuracy of dodgeball:  0% ( 0/37)\n",
            "Test Accuracy of doing aerobics:  0% ( 0/22)\n",
            "Test Accuracy of doing laundry:  0% ( 0/21)\n",
            "Test Accuracy of doing nails: 34% (14/41)\n",
            "Test Accuracy of drawing:  0% ( 0/24)\n",
            "Test Accuracy of dribbling basketball: 55% (21/38)\n",
            "Test Accuracy of drinking:  0% ( 0/21)\n",
            "Test Accuracy of drinking beer:  5% ( 1/17)\n",
            "Test Accuracy of drinking shots:  0% ( 0/13)\n",
            "Test Accuracy of driving car: 56% (27/48)\n",
            "Test Accuracy of driving tractor: 38% (16/42)\n",
            "Test Accuracy of drop kicking:  0% ( 0/10)\n",
            "Test Accuracy of drumming fingers: 41% ( 5/12)\n",
            "Test Accuracy of dunking basketball: 22% ( 8/35)\n",
            "Test Accuracy of dying hair: 40% (21/52)\n",
            "Test Accuracy of eating burger: 35% (14/40)\n",
            "Test Accuracy of eating cake:  0% ( 0/22)\n",
            "Test Accuracy of eating carrots:  5% ( 1/19)\n",
            "Test Accuracy of eating chips:  0% ( 0/26)\n",
            "Test Accuracy of eating doughnuts:  0% ( 0/24)\n",
            "Test Accuracy of eating hotdog:  0% ( 0/30)\n",
            "Test Accuracy of eating ice cream: 19% ( 9/46)\n",
            "Test Accuracy of eating spaghetti: 59% (26/44)\n",
            "Test Accuracy of eating watermelon: 25% ( 8/32)\n",
            "Test Accuracy of egg hunting: 30% ( 6/20)\n",
            "Test Accuracy of exercising arm:  0% ( 0/14)\n",
            "Test Accuracy of exercising with an exercise ball: 44% ( 8/18)\n",
            "Test Accuracy of extinguishing fire: 14% ( 4/28)\n",
            "Test Accuracy of faceplanting:  0% ( 0/19)\n",
            "Test Accuracy of feeding birds: 33% (20/59)\n",
            "Test Accuracy of feeding fish: 16% ( 9/54)\n",
            "Test Accuracy of feeding goats: 56% (27/48)\n",
            "Test Accuracy of filling eyebrows: 65% (30/46)\n",
            "Test Accuracy of finger snapping:  0% ( 0/23)\n",
            "Test Accuracy of fixing hair:  3% ( 1/32)\n",
            "Test Accuracy of flipping pancake:  3% ( 1/27)\n",
            "Test Accuracy of flying kite: 72% (31/43)\n",
            "Test Accuracy of folding clothes:  0% ( 0/32)\n",
            "Test Accuracy of folding napkins: 41% (19/46)\n",
            "Test Accuracy of folding paper: 63% (19/30)\n",
            "Test Accuracy of front raises: 17% ( 7/41)\n",
            "Test Accuracy of frying vegetables: 28% ( 7/25)\n",
            "Test Accuracy of garbage collecting: 31% ( 7/22)\n",
            "Test Accuracy of gargling:  0% ( 0/22)\n",
            "Test Accuracy of getting a haircut: 64% (18/28)\n",
            "Test Accuracy of getting a tattoo: 35% (14/39)\n",
            "Test Accuracy of giving or receiving award: 18% ( 7/38)\n",
            "Test Accuracy of golf chipping: 13% ( 6/44)\n",
            "Test Accuracy of golf driving: 33% (13/39)\n",
            "Test Accuracy of golf putting: 67% (33/49)\n",
            "Test Accuracy of grinding meat: 27% ( 6/22)\n",
            "Test Accuracy of grooming dog: 22% ( 5/22)\n",
            "Test Accuracy of grooming horse: 26% ( 8/30)\n",
            "Test Accuracy of gymnastics tumbling: 44% (21/47)\n",
            "Test Accuracy of hammer throw: 43% (22/51)\n",
            "Test Accuracy of headbanging:  2% ( 1/43)\n",
            "Test Accuracy of headbutting:  0% ( 0/16)\n",
            "Test Accuracy of high jump: 53% (17/32)\n",
            "Test Accuracy of high kick:  0% ( 0/37)\n",
            "Test Accuracy of hitting baseball: 39% (20/51)\n",
            "Test Accuracy of hockey stop:  0% ( 0/18)\n",
            "Test Accuracy of holding snake:  0% ( 0/24)\n",
            "Test Accuracy of hopscotch: 21% ( 8/37)\n",
            "Test Accuracy of hoverboarding:  0% ( 0/21)\n",
            "Test Accuracy of hugging:  0% ( 0/24)\n",
            "Test Accuracy of hula hooping: 34% (20/58)\n",
            "Test Accuracy of hurdling: 45% (11/24)\n",
            "Test Accuracy of hurling (sport): 60% (23/38)\n",
            "Test Accuracy of ice climbing: 76% (38/50)\n",
            "Test Accuracy of ice fishing: 34% (11/32)\n",
            "Test Accuracy of ice skating: 40% (21/52)\n",
            "Test Accuracy of ironing: 15% ( 2/13)\n",
            "Test Accuracy of javelin throw: 29% (11/37)\n",
            "Test Accuracy of jetskiing: 51% (24/47)\n",
            "Test Accuracy of jogging:  0% ( 0/24)\n",
            "Test Accuracy of juggling balls:  0% ( 0/38)\n",
            "Test Accuracy of juggling fire: 20% ( 5/25)\n",
            "Test Accuracy of juggling soccer ball:  0% ( 0/18)\n",
            "Test Accuracy of jumping into pool: 45% (20/44)\n",
            "Test Accuracy of jumpstyle dancing:  3% ( 1/28)\n",
            "Test Accuracy of kicking field goal: 51% (18/35)\n",
            "Test Accuracy of kicking soccer ball:  6% ( 2/32)\n",
            "Test Accuracy of kissing:  0% ( 0/20)\n",
            "Test Accuracy of kitesurfing: 50% (17/34)\n",
            "Test Accuracy of knitting: 68% (24/35)\n",
            "Test Accuracy of krumping: 18% ( 5/27)\n",
            "Test Accuracy of laughing:  0% ( 0/43)\n",
            "Test Accuracy of laying bricks: 22% ( 4/18)\n",
            "Test Accuracy of long jump: 26% ( 9/34)\n",
            "Test Accuracy of lunge: 15% ( 5/33)\n",
            "Test Accuracy of making a cake:  0% ( 0/19)\n",
            "Test Accuracy of making a sandwich:  4% ( 1/22)\n",
            "Test Accuracy of making bed: 48% (13/27)\n",
            "Test Accuracy of making jewelry: 12% ( 4/32)\n",
            "Test Accuracy of making pizza: 23% (12/51)\n",
            "Test Accuracy of making snowman: 55% (16/29)\n",
            "Test Accuracy of making sushi: 20% ( 5/24)\n",
            "Test Accuracy of making tea:  0% ( 0/15)\n",
            "Test Accuracy of marching: 15% ( 9/59)\n",
            "Test Accuracy of massaging back: 62% (22/35)\n",
            "Test Accuracy of massaging feet:  0% ( 0/20)\n",
            "Test Accuracy of massaging legs: 27% ( 5/18)\n",
            "Test Accuracy of massaging person's head:  0% ( 0/20)\n",
            "Test Accuracy of milking cow: 28% (14/50)\n",
            "Test Accuracy of mopping floor:  4% ( 1/21)\n",
            "Test Accuracy of motorcycling: 52% (26/50)\n",
            "Test Accuracy of moving furniture:  0% ( 0/24)\n",
            "Test Accuracy of mowing lawn: 18% ( 9/49)\n",
            "Test Accuracy of news anchoring: 25% ( 5/20)\n",
            "Test Accuracy of opening bottle:  3% ( 1/33)\n",
            "Test Accuracy of opening present: 22% (10/45)\n",
            "Test Accuracy of paragliding: 52% (21/40)\n",
            "Test Accuracy of parasailing: 51% (17/33)\n",
            "Test Accuracy of parkour:  0% ( 0/24)\n",
            "Test Accuracy of passing American football (in game): 81% (36/44)\n",
            "Test Accuracy of passing American football (not in game): 11% ( 6/51)\n",
            "Test Accuracy of peeling apples: 20% ( 6/30)\n",
            "Test Accuracy of peeling potatoes:  0% ( 0/24)\n",
            "Test Accuracy of petting animal (not cat):  7% ( 3/38)\n",
            "Test Accuracy of petting cat: 46% (20/43)\n",
            "Test Accuracy of picking fruit: 40% (16/40)\n",
            "Test Accuracy of planting trees: 21% ( 6/28)\n",
            "Test Accuracy of plastering:  0% ( 0/22)\n",
            "Test Accuracy of playing accordion: 78% (29/37)\n",
            "Test Accuracy of playing badminton: 27% (11/40)\n",
            "Test Accuracy of playing bagpipes:  2% ( 1/40)\n",
            "Test Accuracy of playing basketball:  2% ( 1/50)\n",
            "Test Accuracy of playing bass guitar: 97% (47/48)\n",
            "Test Accuracy of playing cards: 47% (17/36)\n",
            "Test Accuracy of playing cello: 60% (27/45)\n",
            "Test Accuracy of playing chess: 78% (22/28)\n",
            "Test Accuracy of playing clarinet: 47% (21/44)\n",
            "Test Accuracy of playing controller: 75% (21/28)\n",
            "Test Accuracy of playing cricket:  0% ( 0/29)\n",
            "Test Accuracy of playing cymbals: 36% ( 8/22)\n",
            "Test Accuracy of playing didgeridoo: 30% (11/36)\n",
            "Test Accuracy of playing drums: 62% (25/40)\n",
            "Test Accuracy of playing flute:  0% ( 0/12)\n",
            "Test Accuracy of playing guitar: 23% (10/43)\n",
            "Test Accuracy of playing harmonica: 13% ( 5/38)\n",
            "Test Accuracy of playing harp: 81% (43/53)\n",
            "Test Accuracy of playing ice hockey: 66% (26/39)\n",
            "Test Accuracy of playing keyboard: 42% ( 8/19)\n",
            "Test Accuracy of playing kickball: 12% ( 3/24)\n",
            "Test Accuracy of playing monopoly: 27% ( 5/18)\n",
            "Test Accuracy of playing organ: 25% ( 7/28)\n",
            "Test Accuracy of playing paintball: 37% (22/59)\n",
            "Test Accuracy of playing piano: 20% ( 4/20)\n",
            "Test Accuracy of playing poker: 28% (12/42)\n",
            "Test Accuracy of playing recorder: 24% (10/41)\n",
            "Test Accuracy of playing saxophone: 31% (14/44)\n",
            "Test Accuracy of playing squash or racquetball: 74% (37/50)\n",
            "Test Accuracy of playing tennis: 70% (44/62)\n",
            "Test Accuracy of playing trombone: 40% (16/40)\n",
            "Test Accuracy of playing trumpet: 32% (16/49)\n",
            "Test Accuracy of playing ukulele: 14% ( 7/49)\n",
            "Test Accuracy of playing violin: 83% (45/54)\n",
            "Test Accuracy of playing volleyball:  5% ( 2/38)\n",
            "Test Accuracy of playing xylophone:  0% ( 0/38)\n",
            "Test Accuracy of pole vault: 39% (15/38)\n",
            "Test Accuracy of presenting weather forecast: 76% (33/43)\n",
            "Test Accuracy of pull ups: 42% (21/50)\n",
            "Test Accuracy of pumping fist:  6% ( 2/32)\n",
            "Test Accuracy of pumping gas: 25% ( 5/20)\n",
            "Test Accuracy of punching bag:  9% ( 3/32)\n",
            "Test Accuracy of punching person (boxing): 13% ( 3/22)\n",
            "Test Accuracy of push up:  0% ( 0/21)\n",
            "Test Accuracy of pushing car:  5% ( 2/38)\n",
            "Test Accuracy of pushing cart: 52% (27/51)\n",
            "Test Accuracy of pushing wheelchair:  4% ( 1/22)\n",
            "Test Accuracy of reading book: 33% (16/48)\n",
            "Test Accuracy of reading newspaper:  7% ( 1/13)\n",
            "Test Accuracy of recording music:  5% ( 1/18)\n",
            "Test Accuracy of riding a bike:  0% ( 0/21)\n",
            "Test Accuracy of riding camel: 31% (10/32)\n",
            "Test Accuracy of riding elephant: 68% (34/50)\n",
            "Test Accuracy of riding mechanical bull: 28% (11/38)\n",
            "Test Accuracy of riding mountain bike: 50% (10/20)\n",
            "Test Accuracy of riding mule:  5% ( 1/17)\n",
            "Test Accuracy of riding or walking with horse: 64% (31/48)\n",
            "Test Accuracy of riding scooter: 19% ( 6/31)\n",
            "Test Accuracy of riding unicycle: 40% (17/42)\n",
            "Test Accuracy of ripping paper:  0% ( 0/24)\n",
            "Test Accuracy of robot dancing:  0% ( 0/29)\n",
            "Test Accuracy of rock climbing: 16% (10/59)\n",
            "Test Accuracy of rock scissors paper:  0% ( 0/12)\n",
            "Test Accuracy of roller skating: 32% (16/50)\n",
            "Test Accuracy of running on treadmill: 13% ( 2/15)\n",
            "Test Accuracy of sailing: 54% (23/42)\n",
            "Test Accuracy of salsa dancing:  5% ( 3/52)\n",
            "Test Accuracy of sanding floor: 53% (16/30)\n",
            "Test Accuracy of scrambling eggs: 57% (19/33)\n",
            "Test Accuracy of scuba diving: 72% (36/50)\n",
            "Test Accuracy of setting table: 10% ( 2/19)\n",
            "Test Accuracy of shaking hands:  0% ( 0/21)\n",
            "Test Accuracy of shaking head:  8% ( 4/47)\n",
            "Test Accuracy of sharpening knives:  0% ( 0/24)\n",
            "Test Accuracy of sharpening pencil: 13% ( 5/38)\n",
            "Test Accuracy of shaving head:  2% ( 1/48)\n",
            "Test Accuracy of shaving legs: 16% ( 4/24)\n",
            "Test Accuracy of shearing sheep: 83% (40/48)\n",
            "Test Accuracy of shining shoes: 31% ( 7/22)\n",
            "Test Accuracy of shooting basketball:  0% ( 0/29)\n",
            "Test Accuracy of shooting goal (soccer):  0% ( 0/12)\n",
            "Test Accuracy of shot put:  7% ( 3/41)\n",
            "Test Accuracy of shoveling snow: 17% ( 7/40)\n",
            "Test Accuracy of shredding paper:  0% ( 0/16)\n",
            "Test Accuracy of shuffling cards: 11% ( 3/26)\n",
            "Test Accuracy of side kick: 45% (21/46)\n",
            "Test Accuracy of sign language interpreting:  0% ( 0/20)\n",
            "Test Accuracy of singing: 10% ( 6/60)\n",
            "Test Accuracy of situp: 13% ( 5/37)\n",
            "Test Accuracy of skateboarding: 28% (21/73)\n",
            "Test Accuracy of ski jumping: 10% ( 4/40)\n",
            "Test Accuracy of skiing (not slalom or crosscountry): 29% (16/54)\n",
            "Test Accuracy of skiing crosscountry:  9% ( 2/21)\n",
            "Test Accuracy of skiing slalom: 31% (12/38)\n",
            "Test Accuracy of skipping rope:  0% ( 0/20)\n",
            "Test Accuracy of skydiving: 16% ( 3/18)\n",
            "Test Accuracy of slacklining: 15% ( 5/33)\n",
            "Test Accuracy of slapping:  0% ( 0/11)\n",
            "Test Accuracy of sled dog racing: 61% (19/31)\n",
            "Test Accuracy of smoking:  2% ( 1/37)\n",
            "Test Accuracy of smoking hookah:  2% ( 1/37)\n",
            "Test Accuracy of snatch weight lifting: 25% (11/43)\n",
            "Test Accuracy of sneezing:  0% ( 0/17)\n",
            "Test Accuracy of sniffing:  0% ( 0/16)\n",
            "Test Accuracy of snorkeling: 48% (31/64)\n",
            "Test Accuracy of snowboarding: 36% (16/44)\n",
            "Test Accuracy of snowkiting: 57% (36/63)\n",
            "Test Accuracy of snowmobiling: 34% (11/32)\n",
            "Test Accuracy of somersaulting:  0% ( 0/33)\n",
            "Test Accuracy of spinning poi: 33% (19/57)\n",
            "Test Accuracy of spray painting: 14% ( 7/48)\n",
            "Test Accuracy of spraying:  5% ( 1/18)\n",
            "Test Accuracy of springboard diving:  6% ( 1/16)\n",
            "Test Accuracy of squat: 38% (14/36)\n",
            "Test Accuracy of sticking tongue out: 23% (11/47)\n",
            "Test Accuracy of stomping grapes: 25% ( 6/24)\n",
            "Test Accuracy of stretching arm:  3% ( 1/31)\n",
            "Test Accuracy of stretching leg: 13% ( 5/38)\n",
            "Test Accuracy of strumming guitar:  4% ( 1/22)\n",
            "Test Accuracy of surfing crowd: 79% (31/39)\n",
            "Test Accuracy of surfing water: 40% (16/40)\n",
            "Test Accuracy of sweeping floor: 54% (12/22)\n",
            "Test Accuracy of swimming backstroke: 77% (38/49)\n",
            "Test Accuracy of swimming breast stroke: 28% (11/38)\n",
            "Test Accuracy of swimming butterfly stroke: 25% ( 9/35)\n",
            "Test Accuracy of swing dancing: 10% ( 3/28)\n",
            "Test Accuracy of swinging legs:  0% ( 0/14)\n",
            "Test Accuracy of swinging on something: 16% ( 3/18)\n",
            "Test Accuracy of sword fighting:  0% ( 0/16)\n",
            "Test Accuracy of tai chi: 18% ( 8/44)\n",
            "Test Accuracy of taking a shower:  0% ( 0/16)\n",
            "Test Accuracy of tango dancing: 49% (28/57)\n",
            "Test Accuracy of tap dancing:  5% ( 2/40)\n",
            "Test Accuracy of tapping guitar:  0% ( 0/32)\n",
            "Test Accuracy of tapping pen:  9% ( 3/31)\n",
            "Test Accuracy of tasting beer: 22% ( 5/22)\n",
            "Test Accuracy of tasting food:  0% ( 0/28)\n",
            "Test Accuracy of testifying: 43% ( 7/16)\n",
            "Test Accuracy of texting: 63% (24/38)\n",
            "Test Accuracy of throwing axe: 46% (15/32)\n",
            "Test Accuracy of throwing ball:  0% ( 0/26)\n",
            "Test Accuracy of throwing discus: 37% (20/54)\n",
            "Test Accuracy of tickling:  8% ( 2/24)\n",
            "Test Accuracy of tobogganing: 34% (14/41)\n",
            "Test Accuracy of tossing coin:  0% ( 0/20)\n",
            "Test Accuracy of tossing salad: 71% (10/14)\n",
            "Test Accuracy of training dog: 16% ( 4/24)\n",
            "Test Accuracy of trapezing: 48% (17/35)\n",
            "Test Accuracy of trimming or shaving beard: 21% ( 9/42)\n",
            "Test Accuracy of trimming trees: 40% (10/25)\n",
            "Test Accuracy of triple jump:  5% ( 1/17)\n",
            "Test Accuracy of tying bow tie:  0% ( 0/14)\n",
            "Test Accuracy of tying knot (not on a tie):  8% ( 3/36)\n",
            "Test Accuracy of tying tie: 60% (17/28)\n",
            "Test Accuracy of unboxing: 39% (15/38)\n",
            "Test Accuracy of unloading truck: 20% ( 5/24)\n",
            "Test Accuracy of using computer: 78% (32/41)\n",
            "Test Accuracy of using remote controller (not gaming): 40% (12/30)\n",
            "Test Accuracy of using segway:  0% ( 0/24)\n",
            "Test Accuracy of vault: 61% (19/31)\n",
            "Test Accuracy of waiting in line: 12% ( 2/16)\n",
            "Test Accuracy of walking the dog:  0% ( 0/49)\n",
            "Test Accuracy of washing dishes: 20% ( 8/40)\n",
            "Test Accuracy of washing feet: 31% (14/45)\n",
            "Test Accuracy of washing hair:  0% ( 0/24)\n",
            "Test Accuracy of washing hands: 50% (17/34)\n",
            "Test Accuracy of water skiing: 51% (20/39)\n",
            "Test Accuracy of water sliding:  0% ( 0/22)\n",
            "Test Accuracy of watering plants: 35% (14/40)\n",
            "Test Accuracy of waxing back: 26% ( 5/19)\n",
            "Test Accuracy of waxing chest: 16% ( 3/18)\n",
            "Test Accuracy of waxing eyebrows: 21% ( 7/32)\n",
            "Test Accuracy of waxing legs: 30% (10/33)\n",
            "Test Accuracy of weaving basket: 70% (24/34)\n",
            "Test Accuracy of welding: 38% (13/34)\n",
            "Test Accuracy of whistling:  0% ( 0/19)\n",
            "Test Accuracy of windsurfing: 63% (33/52)\n",
            "Test Accuracy of wrapping present: 34% (13/38)\n",
            "Test Accuracy of wrestling: 12% ( 3/24)\n",
            "Test Accuracy of writing: 50% (19/38)\n",
            "Test Accuracy of yawning: 16% ( 2/12)\n",
            "Test Accuracy of  yoga: 42% (19/45)\n",
            "Test Accuracy of zumba: 44% (20/45)\n",
            "Test Accuracy of 29% (3928/13504)\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0 for i in range(len(classes)))\n",
        "class_total = list(0 for i in range(len(classes)))\n",
        "model.eval()\n",
        "\n",
        "for data, target in tqdm(test_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    with torch.no_grad(): # turn off autograd for faster testing\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "    test_loss = loss.item() * data.size(0)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    if len(target) == 64:\n",
        "        for i in range(64):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss / test_data_len\n",
        "print('Test Loss: {:.4f}'.format(test_loss))\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n",
        "            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n",
        "        ))\n",
        "    else:\n",
        "        print(\"Test accuracy of %5s: NA\" % (classes[i]))\n",
        "print(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n",
        "            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DKYgdQBCb4Nb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "eac04b4e-612c-46de-b082-2ce1348c0faf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f91e47705c3a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraced_script_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraced_script_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HAR(kinetics-400).pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "example = torch.rand(1, 3, 224, 224)\n",
        "traced_script_module = torch.jit.trace(model.cpu(), example)\n",
        "traced_script_module.save(\"HAR(kinetics-400).pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjCVuKxritR8"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe4o16s-j2Lh",
        "outputId": "86e3e555-5b79-4fec-fe9c-b1e19f1db9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "DCsQomORkjkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch\n",
        "\n",
        "# Define the path to your .pt model file\n",
        "model_path = '/content/HAR(UCF-101).pt'\n",
        "\n",
        "# Load the model\n",
        "model = torch.load(model_path)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "# Define your image preprocessing transformations\n",
        "transform = T.Compose([ # We dont need augmentation for test transforms\n",
        "          T.Resize(256),\n",
        "          T.CenterCrop(224),\n",
        "          T.ToTensor(),\n",
        "          T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n",
        "      ])\n",
        "\n",
        "# Load and preprocess your image\n",
        "image_path = '/content/180.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "\n",
        "# Get the predicted class label\n",
        "_, predicted_class = torch.max(output, 1)\n",
        "predicted_class = predicted_class.item()\n",
        "\n",
        "# Print the predicted class label\n",
        "print(\"Predicted class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNH1me0LiUwN",
        "outputId": "0e0b0d2d-0e92-4847-9402-06771957593b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:799: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
            "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MBOmJhIyijHW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}